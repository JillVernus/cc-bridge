package handlers

import (
	"bufio"
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/JillVernus/cc-bridge/internal/apikey"
	"github.com/JillVernus/cc-bridge/internal/auth/codex"
	"github.com/JillVernus/cc-bridge/internal/config"
	"github.com/JillVernus/cc-bridge/internal/converters"
	"github.com/JillVernus/cc-bridge/internal/httpclient"
	"github.com/JillVernus/cc-bridge/internal/middleware"
	"github.com/JillVernus/cc-bridge/internal/pricing"
	"github.com/JillVernus/cc-bridge/internal/providers"
	"github.com/JillVernus/cc-bridge/internal/quota"
	"github.com/JillVernus/cc-bridge/internal/requestlog"
	"github.com/JillVernus/cc-bridge/internal/scheduler"
	"github.com/JillVernus/cc-bridge/internal/session"
	"github.com/JillVernus/cc-bridge/internal/types"
	"github.com/JillVernus/cc-bridge/internal/utils"
	"github.com/gin-gonic/gin"
	"github.com/tidwall/gjson"
)

// codexTokenManager is a shared token manager for OAuth token refresh
var codexTokenManager = codex.NewTokenManager()

// trackResponsesUsage tracks usage for Responses API channels based on quota type
func trackResponsesUsage(usageManager *quota.UsageManager, upstream *config.UpstreamConfig, model string, cost float64) {
	if usageManager == nil || upstream.QuotaType == "" {
		return
	}

	// Check if this model should be counted for quota
	if !upstream.ShouldCountQuota(model) {
		return
	}

	var amount float64
	switch upstream.QuotaType {
	case "requests":
		amount = 1
	case "credit":
		amount = cost
	default:
		return
	}

	if err := usageManager.IncrementResponsesUsage(upstream.Index, amount); err != nil {
		log.Printf("âš ï¸ é…é¢ä½¿ç”¨é‡è¿½è¸ªå¤±è´¥ (Responses, channelIndex=%d): %v", upstream.Index, err)
	}
}

// ResponsesHandler Responses API ä»£ç†å¤„ç†å™¨
// æ”¯æŒå¤šæ¸ é“è°ƒåº¦ï¼šå½“é…ç½®å¤šä¸ªæ¸ é“æ—¶è‡ªåŠ¨å¯ç”¨
func ResponsesHandler(
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	channelScheduler *scheduler.ChannelScheduler,
	reqLogManager *requestlog.Manager,
) gin.HandlerFunc {
	return ResponsesHandlerWithAPIKey(envCfg, cfgManager, sessionManager, channelScheduler, reqLogManager, nil, nil)
}

// ResponsesHandlerWithAPIKey Responses API ä»£ç†å¤„ç†å™¨ï¼ˆæ”¯æŒ API Key éªŒè¯ï¼‰
func ResponsesHandlerWithAPIKey(
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	channelScheduler *scheduler.ChannelScheduler,
	reqLogManager *requestlog.Manager,
	apiKeyManager *apikey.Manager,
	usageManager *quota.UsageManager,
) gin.HandlerFunc {
	return gin.HandlerFunc(func(c *gin.Context) {
		// å…ˆè¿›è¡Œè®¤è¯ï¼ˆå¦‚æœä¸Šæ¸¸ä¸­é—´ä»¶å°šæœªå®Œæˆè®¤è¯ï¼‰
		if _, exists := c.Get(middleware.ContextKeyAPIKeyID); !exists {
			middleware.ProxyAuthMiddlewareWithAPIKey(envCfg, apiKeyManager)(c)
			if c.IsAborted() {
				return
			}
		}

		// Check endpoint permission
		if vk, exists := c.Get(middleware.ContextKeyValidatedKey); exists {
			if validatedKey, ok := vk.(*apikey.ValidatedKey); ok && validatedKey != nil {
				if !validatedKey.CheckEndpointPermission("responses") {
					c.JSON(403, gin.H{
						"error": "Endpoint /v1/responses not allowed for this API key",
						"code":  "ENDPOINT_NOT_ALLOWED",
					})
					return
				}
			}
		}

		startTime := time.Now()

		// è¯»å–åŸå§‹è¯·æ±‚ä½“
		maxBodyMB := envCfg.MaxRequestBodyMB
		if maxBodyMB <= 0 {
			maxBodyMB = 20
		}
		c.Request.Body = http.MaxBytesReader(c.Writer, c.Request.Body, int64(maxBodyMB)*1024*1024)

		bodyBytes, err := io.ReadAll(c.Request.Body)
		if err != nil {
			var maxBytesErr *http.MaxBytesError
			if errors.As(err, &maxBytesErr) {
				c.JSON(http.StatusRequestEntityTooLarge, gin.H{
					"error":   "Request body too large",
					"message": fmt.Sprintf("Maximum allowed request size is %d MB", maxBodyMB),
				})
				return
			}
			c.JSON(400, gin.H{"error": "Failed to read request body"})
			return
		}
		// æ¢å¤è¯·æ±‚ä½“ä¾›åç»­ä½¿ç”¨
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		// Store request data for debug logging
		StoreDebugRequestData(c, bodyBytes)

		// è§£æ Responses è¯·æ±‚
		var responsesReq types.ResponsesRequest
		if len(bodyBytes) > 0 {
			_ = json.Unmarshal(bodyBytes, &responsesReq)
		}

		// Check model permission
		if vk, exists := c.Get(middleware.ContextKeyValidatedKey); exists {
			if validatedKey, ok := vk.(*apikey.ValidatedKey); ok && validatedKey != nil {
				if !validatedKey.CheckModelPermission(responsesReq.Model) {
					c.JSON(403, gin.H{
						"error": fmt.Sprintf("Model %s not allowed for this API key", responsesReq.Model),
						"code":  "MODEL_NOT_ALLOWED",
					})
					return
				}
			}
		}

		// æå–å¯¹è¯æ ‡è¯†ç”¨äº Trace äº²å’Œæ€§ + è®°å½• user/session
		// - Codexï¼šuser_id ç»Ÿä¸€è®°å½•ä¸º "codex"ï¼Œsession_id ä½¿ç”¨ prompt_cache_keyï¼ˆä¼šè¯çº§æ ‡è¯†ï¼‰
		// - Claudeï¼šä½¿ç”¨å¤åˆ user_id è§£æå‡º user_id + session_id
		promptCacheKey := strings.TrimSpace(gjson.GetBytes(bodyBytes, "prompt_cache_key").String())
		compoundUserID := ""
		userID := ""
		sessionID := ""
		if promptCacheKey != "" {
			userID = "codex"
			sessionID = promptCacheKey
			compoundUserID = promptCacheKey
		} else {
			// ä¼˜å…ˆçº§: Conversation_id Header > Session_id Header > prompt_cache_key > metadata.user_id
			compoundUserID = extractConversationID(c, bodyBytes)
			userID, sessionID = parseClaudeCodeUserID(compoundUserID)
		}

		// æå– reasoning.effort ç”¨äºæ—¥å¿—æ˜¾ç¤º
		reasoningEffort := gjson.GetBytes(bodyBytes, "reasoning.effort").String()

		// æå– API Key ID ç”¨äºè¯·æ±‚æ—¥å¿— (nil è¡¨ç¤ºæœªè®¾ç½®)
		var apiKeyID *int64
		if id, exists := c.Get(middleware.ContextKeyAPIKeyID); exists {
			if idVal, ok := id.(int64); ok {
				apiKeyID = &idVal
			}
		}

		// åˆ›å»º pending è¯·æ±‚æ—¥å¿—è®°å½•
		var requestLogID string
		if reqLogManager != nil {
			pendingLog := &requestlog.RequestLog{
				Status:          requestlog.StatusPending,
				InitialTime:     startTime,
				Model:           responsesReq.Model,
				ReasoningEffort: reasoningEffort,
				Stream:          responsesReq.Stream,
				Endpoint:        "/v1/responses",
				ClientID:        userID,
				SessionID:       sessionID,
				APIKeyID:        apiKeyID,
			}
			if err := reqLogManager.Add(pendingLog); err != nil {
				log.Printf("âš ï¸ åˆ›å»º pending è¯·æ±‚æ—¥å¿—å¤±è´¥: %v", err)
			} else {
				requestLogID = pendingLog.ID
			}
		}

		// æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¸ é“æ¨¡å¼
		isMultiChannel := channelScheduler.IsMultiChannelMode(true) // true = isResponses

		// Get allowed channels from API key permissions
		var allowedChannels []int
		if vk, exists := c.Get(middleware.ContextKeyValidatedKey); exists {
			if validatedKey, ok := vk.(*apikey.ValidatedKey); ok && validatedKey != nil {
				allowedChannels = validatedKey.GetAllowedChannels(true) // true = Responses API
			}
		}

		if isMultiChannel {
			// Multi-channel mode: use scheduler with failover
			handleMultiChannelResponses(c, envCfg, cfgManager, channelScheduler, sessionManager, bodyBytes, responsesReq, userID, sessionID, apiKeyID, reasoningEffort, startTime, reqLogManager, requestLogID, usageManager, allowedChannels)
		} else {
			// å•æ¸ é“æ¨¡å¼ï¼šä½¿ç”¨ç°æœ‰é€»è¾‘
			handleSingleChannelResponses(c, envCfg, cfgManager, sessionManager, bodyBytes, responsesReq, startTime, reqLogManager, requestLogID, usageManager, allowedChannels)
		}
	})
}

// handleMultiChannelResponses handles multi-channel Responses API requests with failover support.
// When a channel fails and there are more channels to try, it logs the failed attempt
// with StatusFailover and creates a new pending log for the next attempt.
func handleMultiChannelResponses(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	channelScheduler *scheduler.ChannelScheduler,
	sessionManager *session.SessionManager,
	bodyBytes []byte,
	responsesReq types.ResponsesRequest,
	clientID string,
	sessionID string,
	apiKeyID *int64,
	reasoningEffort string,
	startTime time.Time,
	reqLogManager *requestlog.Manager,
	requestLogID string,
	usageManager *quota.UsageManager,
	allowedChannels []int,
) {
	failedChannels := make(map[int]bool)
	var lastError error
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}
	var lastFailedUpstream *config.UpstreamConfig

	maxChannelAttempts := channelScheduler.GetActiveChannelCount(true) // true = isResponses

	for channelAttempt := 0; channelAttempt < maxChannelAttempts; channelAttempt++ {
		selection, err := channelScheduler.SelectChannel(c.Request.Context(), clientID, failedChannels, true, allowedChannels)
		if err != nil {
			lastError = err
			break
		}

		upstream := selection.Upstream
		channelIndex := selection.ChannelIndex

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ¯ [Multi-Channel/Responses] Selected channel: [%d] %s (reason: %s, attempt %d/%d)",
				channelIndex, upstream.Name, selection.Reason, channelAttempt+1, maxChannelAttempts)
		}

		success, failoverErr := tryResponsesChannelWithAllKeys(c, envCfg, cfgManager, sessionManager, upstream, bodyBytes, responsesReq, startTime, reqLogManager, requestLogID, usageManager)

		if success {
			channelScheduler.RecordSuccess(channelIndex, true)
			channelScheduler.SetTraceAffinity(clientID, channelIndex)
			return
		}

		// Channel failed: record failure metrics
		channelScheduler.RecordFailure(channelIndex, true)
		failedChannels[channelIndex] = true

		// Check if there are more channels to try
		hasMoreChannels := channelAttempt < maxChannelAttempts-1 && len(failedChannels) < maxChannelAttempts

		if hasMoreChannels {
			// Failover case: log this failed attempt and create new pending log for next attempt
			if reqLogManager != nil && requestLogID != "" {
				completeTime := time.Now()
				httpStatus := 0
				upstreamErr := ""
				if failoverErr != nil {
					httpStatus = failoverErr.Status
					upstreamErr = string(failoverErr.Body)
				}

				// Update current log as failover (keeping original error info)
				failoverRecord := &requestlog.RequestLog{
					Status:          requestlog.StatusFailover,
					CompleteTime:    completeTime,
					DurationMs:      completeTime.Sub(startTime).Milliseconds(),
					Type:            upstream.ServiceType,
					ProviderName:    upstream.Name,
					Model:           responsesReq.Model,
					ReasoningEffort: reasoningEffort,
					ChannelID:       channelIndex,
					ChannelName:     upstream.Name,
					HTTPStatus:      httpStatus,
					Error:           fmt.Sprintf("failover to next channel (%d/%d)", channelAttempt+1, maxChannelAttempts),
					UpstreamError:   upstreamErr,
				}
				if err := reqLogManager.Update(requestLogID, failoverRecord); err != nil {
					log.Printf("âš ï¸ Failed to update failover log: %v", err)
				}

				// Create new pending log for next channel attempt
				newPendingLog := &requestlog.RequestLog{
					Status:          requestlog.StatusPending,
					InitialTime:     time.Now(),
					Model:           responsesReq.Model,
					ReasoningEffort: reasoningEffort,
					Stream:          responsesReq.Stream,
					Endpoint:        "/v1/responses",
					ClientID:        clientID,
					SessionID:       sessionID,
					APIKeyID:        apiKeyID,
				}
				if err := reqLogManager.Add(newPendingLog); err != nil {
					log.Printf("âš ï¸ Failed to create failover pending log: %v", err)
				} else {
					requestLogID = newPendingLog.ID
					startTime = newPendingLog.InitialTime
				}
			}

			log.Printf("âš ï¸ [Multi-Channel/Responses] Channel [%d] %s all keys failed, trying next channel", channelIndex, upstream.Name)
		}

		if failoverErr != nil {
			lastFailoverError = failoverErr
			lastError = fmt.Errorf("channel [%d] %s failed", channelIndex, upstream.Name)
			lastFailedUpstream = upstream
		}
	}

	// All channels failed
	log.Printf("ğŸ’¥ [Multi-Channel/Responses] All channels failed")

	// Update request log with final error status
	if reqLogManager != nil && requestLogID != "" {
		httpStatus := 503
		errMsg := "all channels unavailable"
		upstreamErr := ""
		if lastFailoverError != nil && lastFailoverError.Status != 0 {
			httpStatus = lastFailoverError.Status
			upstreamErr = string(lastFailoverError.Body)
		}
		if lastError != nil {
			errMsg = lastError.Error()
		}
		record := &requestlog.RequestLog{
			Status:          requestlog.StatusError,
			CompleteTime:    time.Now(),
			DurationMs:      time.Since(startTime).Milliseconds(),
			Model:           responsesReq.Model,
			ReasoningEffort: reasoningEffort,
			HTTPStatus:      httpStatus,
			Error:           errMsg,
			UpstreamError:   upstreamErr,
		}
		if lastFailedUpstream != nil {
			record.Type = lastFailedUpstream.ServiceType
			record.ProviderName = lastFailedUpstream.Name
			record.ChannelID = lastFailedUpstream.Index
			record.ChannelName = lastFailedUpstream.Name
		}
		_ = reqLogManager.Update(requestLogID, record)
	}

	// Return error response to client
	if lastFailoverError != nil {
		status := lastFailoverError.Status
		if status == 0 {
			status = 503
		}
		var errBody map[string]interface{}
		if err := json.Unmarshal(lastFailoverError.Body, &errBody); err == nil {
			c.JSON(status, errBody)
		} else {
			c.JSON(status, gin.H{"error": string(lastFailoverError.Body)})
		}
	} else {
		errMsg := "all channels unavailable"
		if lastError != nil {
			errMsg = lastError.Error()
		}
		c.JSON(503, gin.H{
			"error":   "all Responses channels unavailable",
			"details": errMsg,
		})
	}
}

// tryResponsesChannelWithAllKeys å°è¯•ä½¿ç”¨ Responses æ¸ é“çš„æ‰€æœ‰å¯†é’¥
func tryResponsesChannelWithAllKeys(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	upstream *config.UpstreamConfig,
	bodyBytes []byte,
	responsesReq types.ResponsesRequest,
	startTime time.Time,
	reqLogManager *requestlog.Manager,
	requestLogID string,
	usageManager *quota.UsageManager,
) (bool, *struct {
	Status int
	Body   []byte
}) {
	// å¤„ç† OpenAI OAuth æ¸ é“ï¼ˆCodexï¼‰
	if upstream.ServiceType == "openai-oauth" {
		return tryResponsesChannelWithOAuth(c, envCfg, cfgManager, sessionManager, upstream, bodyBytes, responsesReq, startTime, reqLogManager, requestLogID, usageManager)
	}

	if len(upstream.APIKeys) == 0 {
		return false, nil
	}

	provider := &providers.ResponsesProvider{SessionManager: sessionManager}

	maxRetries := len(upstream.APIKeys)
	failedKeys := make(map[string]bool)
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}
	deprioritizeCandidates := make(map[string]bool)

	for attempt := 0; attempt < maxRetries; attempt++ {
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		apiKey, err := cfgManager.GetNextResponsesAPIKey(upstream, failedKeys)
		if err != nil {
			break
		}

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ”‘ [Responses] ä½¿ç”¨APIå¯†é’¥: %s (å°è¯• %d/%d)", maskAPIKey(apiKey), attempt+1, maxRetries)
		}

		providerReq, _, err := provider.ConvertToProviderRequest(c, upstream, apiKey)
		if err != nil {
			failedKeys[apiKey] = true
			continue
		}

		resp, err := sendResponsesRequest(providerReq, upstream, envCfg, responsesReq.Stream)
		if err != nil {
			failedKeys[apiKey] = true
			cfgManager.MarkKeyAsFailed(apiKey)
			log.Printf("âš ï¸ [Responses] APIå¯†é’¥å¤±è´¥: %v", err)
			continue
		}

		if resp.StatusCode < 200 || resp.StatusCode >= 300 {
			respBodyBytes, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			respBodyBytes = utils.DecompressGzipIfNeeded(resp, respBodyBytes)

			shouldFailover, isQuotaRelated := shouldRetryWithNextKey(resp.StatusCode, respBodyBytes)
			if shouldFailover {
				failedKeys[apiKey] = true
				cfgManager.MarkKeyAsFailed(apiKey)
				log.Printf("âš ï¸ [Responses] APIå¯†é’¥å¤±è´¥ (çŠ¶æ€: %d)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¯†é’¥", resp.StatusCode)

				lastFailoverError = &struct {
					Status int
					Body   []byte
				}{
					Status: resp.StatusCode,
					Body:   respBodyBytes,
				}

				if isQuotaRelated {
					deprioritizeCandidates[apiKey] = true
				}
				continue
			}

			c.Data(resp.StatusCode, "application/json", respBodyBytes)
			return true, nil
		}

		if len(deprioritizeCandidates) > 0 {
			for key := range deprioritizeCandidates {
				_ = cfgManager.DeprioritizeAPIKey(key)
			}
		}

		handleResponsesSuccess(c, resp, provider, upstream, envCfg, cfgManager, sessionManager, startTime, &responsesReq, bodyBytes, reqLogManager, requestLogID, usageManager)
		return true, nil
	}

	return false, lastFailoverError
}

// tryResponsesChannelWithOAuth ä½¿ç”¨ OAuth è®¤è¯å°è¯• Responses è¯·æ±‚ï¼ˆCodexï¼‰
func tryResponsesChannelWithOAuth(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	upstream *config.UpstreamConfig,
	bodyBytes []byte,
	responsesReq types.ResponsesRequest,
	startTime time.Time,
	reqLogManager *requestlog.Manager,
	requestLogID string,
	usageManager *quota.UsageManager,
) (bool, *struct {
	Status int
	Body   []byte
}) {
	// è¾…åŠ©å‡½æ•°ï¼šæ›´æ–°è¯·æ±‚æ—¥å¿—ä¸ºé”™è¯¯çŠ¶æ€
	updateErrorLog := func(httpStatus int, errMsg string) {
		if reqLogManager != nil && requestLogID != "" {
			completeTime := time.Now()
			record := &requestlog.RequestLog{
				Status:        requestlog.StatusError,
				CompleteTime:  completeTime,
				DurationMs:    completeTime.Sub(startTime).Milliseconds(),
				Type:          "openai-oauth",
				ProviderName:  upstream.Name,
				HTTPStatus:    httpStatus,
				ChannelID:     upstream.Index,
				ChannelName:   upstream.Name,
				UpstreamError: errMsg,
			}
			if err := reqLogManager.Update(requestLogID, record); err != nil {
				log.Printf("âš ï¸ è¯·æ±‚æ—¥å¿—æ›´æ–°å¤±è´¥: %v", err)
			}
		}
	}

	if upstream.OAuthTokens == nil {
		errMsg := "OAuth tokens not configured for this channel"
		log.Printf("âš ï¸ [OAuth] æ¸ é“ %s æœªé…ç½® OAuth tokens", upstream.Name)
		updateErrorLog(503, errMsg)
		return false, &struct {
			Status int
			Body   []byte
		}{
			Status: 503,
			Body:   []byte(fmt.Sprintf(`{"error":"%s"}`, errMsg)),
		}
	}

	// è·å–æœ‰æ•ˆçš„ OAuth tokenï¼ˆå¦‚æœè¿‡æœŸä¼šè‡ªåŠ¨åˆ·æ–°ï¼‰
	accessToken, accountID, updatedTokens, err := codexTokenManager.GetValidToken(upstream.OAuthTokens)
	if err != nil {
		errMsg := fmt.Sprintf("Failed to get valid OAuth token: %s", err.Error())
		log.Printf("âš ï¸ [OAuth] è·å–æœ‰æ•ˆ token å¤±è´¥: %v", err)
		updateErrorLog(401, errMsg)
		return false, &struct {
			Status int
			Body   []byte
		}{
			Status: 401,
			Body:   []byte(fmt.Sprintf(`{"error":"%s"}`, errMsg)),
		}
	}

	// å¦‚æœ token è¢«åˆ·æ–°äº†ï¼Œä¿å­˜åˆ°é…ç½®ä¸­
	if updatedTokens != nil {
		if err := cfgManager.UpdateResponsesOAuthTokensByName(upstream.Name, updatedTokens); err != nil {
			log.Printf("âš ï¸ [OAuth] ä¿å­˜åˆ·æ–°åçš„ token å¤±è´¥: %v", err)
		} else {
			log.Printf("âœ… [OAuth] Token å·²åˆ·æ–°å¹¶ä¿å­˜")
		}
	}

	c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

	if envCfg.ShouldLog("info") {
		log.Printf("ğŸ” [OAuth] ä½¿ç”¨ Codex OAuth è®¤è¯ (Account: %s...)", accountID[:12])
	}

	// æ„å»º OAuth è¯·æ±‚
	providerReq, err := buildCodexOAuthRequest(c, upstream, bodyBytes, responsesReq, accessToken, accountID)
	if err != nil {
		errMsg := fmt.Sprintf("Failed to build OAuth request: %s", err.Error())
		log.Printf("âš ï¸ [OAuth] æ„å»ºè¯·æ±‚å¤±è´¥: %v", err)
		updateErrorLog(500, errMsg)
		return false, &struct {
			Status int
			Body   []byte
		}{
			Status: 500,
			Body:   []byte(fmt.Sprintf(`{"error":"%s"}`, errMsg)),
		}
	}

	resp, err := sendResponsesRequest(providerReq, upstream, envCfg, responsesReq.Stream)
	if err != nil {
		errMsg := fmt.Sprintf("Request failed: %s", err.Error())
		log.Printf("âš ï¸ [OAuth] è¯·æ±‚å¤±è´¥: %v", err)
		updateErrorLog(502, errMsg)
		return false, &struct {
			Status int
			Body   []byte
		}{
			Status: 502,
			Body:   []byte(fmt.Sprintf(`{"error":"%s"}`, errMsg)),
		}
	}

	if resp.StatusCode < 200 || resp.StatusCode >= 300 {
		respBodyBytes, _ := io.ReadAll(resp.Body)
		resp.Body.Close()
		respBodyBytes = utils.DecompressGzipIfNeeded(resp, respBodyBytes)

		log.Printf("âš ï¸ [OAuth] Codex API è¿”å›é”™è¯¯: %d - %s", resp.StatusCode, string(respBodyBytes))

		// æ›´æ–°è¯·æ±‚æ—¥å¿—ä¸ºé”™è¯¯çŠ¶æ€
		updateErrorLog(resp.StatusCode, string(respBodyBytes))

		// å¯¹äº 429 é”™è¯¯ï¼Œè®°å½•é…é¢è¶…é™çŠ¶æ€
		if resp.StatusCode == 429 {
			retryAfter := quota.ParseRetryAfter(resp.Header.Get("Retry-After"))
			quota.GetManager().SetExceeded(upstream.Index, upstream.Name, "rate_limit_exceeded", retryAfter)
		}

		// å¯¹äº 401 é”™è¯¯ï¼Œå°è¯•å¼ºåˆ¶åˆ·æ–° token
		if resp.StatusCode == 401 {
			log.Printf("ğŸ”„ [OAuth] 401 é”™è¯¯ï¼Œå°è¯•å¼ºåˆ¶åˆ·æ–° token...")
			newTokens, refreshErr := codexTokenManager.RefreshTokensWithRetry(upstream.OAuthTokens.RefreshToken, 2)
			if refreshErr == nil {
				if saveErr := cfgManager.UpdateResponsesOAuthTokensByName(upstream.Name, newTokens); saveErr != nil {
					log.Printf("âš ï¸ [OAuth] ä¿å­˜åˆ·æ–°åçš„ token å¤±è´¥: %v", saveErr)
				}
			}
		}

		return false, &struct {
			Status int
			Body   []byte
		}{
			Status: resp.StatusCode,
			Body:   respBodyBytes,
		}
	}

	// æ›´æ–°é…é¢ä¿¡æ¯ä»å“åº”å¤´
	quota.GetManager().UpdateFromHeaders(upstream.Index, upstream.Name, resp.Header)

	provider := &providers.ResponsesProvider{SessionManager: sessionManager}
	handleResponsesSuccess(c, resp, provider, upstream, envCfg, cfgManager, sessionManager, startTime, &responsesReq, bodyBytes, reqLogManager, requestLogID, usageManager)
	return true, nil
}

// buildCodexOAuthRequest æ„å»º Codex OAuth API è¯·æ±‚
func buildCodexOAuthRequest(
	c *gin.Context,
	upstream *config.UpstreamConfig,
	bodyBytes []byte,
	responsesReq types.ResponsesRequest,
	accessToken string,
	accountID string,
) (*http.Request, error) {
	// è§£æè¯·æ±‚ä½“ä¸º map ä»¥ä¿ç•™æ‰€æœ‰å­—æ®µ
	var reqMap map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &reqMap); err != nil {
		return nil, fmt.Errorf("è§£æè¯·æ±‚å¤±è´¥: %w", err)
	}

	// æ¨¡å‹é‡å®šå‘
	if model, ok := reqMap["model"].(string); ok {
		reqMap["model"] = config.RedirectModel(model, upstream)
	}

	// åºåˆ—åŒ–è¯·æ±‚ä½“
	reqBody, err := json.Marshal(reqMap)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
	}

	// Codex OAuth ä½¿ç”¨å›ºå®šçš„ API ç«¯ç‚¹
	targetURL := "https://chatgpt.com/backend-api/codex/responses"

	req, err := http.NewRequest("POST", targetURL, bytes.NewReader(reqBody))
	if err != nil {
		return nil, err
	}

	// æ„å»º OAuth è¯·æ±‚å¤´è¾“å…¥ï¼Œè½¬å‘åŸå§‹è¯·æ±‚çš„å…³é”®å¤´éƒ¨
	headerInput := utils.CodexOAuthHeadersInput{
		AccessToken:    accessToken,
		AccountID:      accountID,
		UserAgent:      c.GetHeader("User-Agent"),
		ConversationID: c.GetHeader("Conversation_id"),
		SessionID:      c.GetHeader("Session_id"),
		Originator:     c.GetHeader("Originator"),
	}

	// å¦‚æœæ˜¯æµå¼è¯·æ±‚ï¼Œç¡®ä¿æ­£ç¡®çš„ Accept å¤´
	if responsesReq.Stream {
		utils.SetCodexOAuthStreamHeaders(req.Header, headerInput)
	} else {
		utils.SetCodexOAuthNonStreamHeaders(req.Header, headerInput)
	}

	return req, nil
}

// handleSingleChannelResponses å¤„ç†å•æ¸ é“ Responses è¯·æ±‚ï¼ˆç°æœ‰é€»è¾‘ï¼‰
func handleSingleChannelResponses(
	c *gin.Context,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	bodyBytes []byte,
	responsesReq types.ResponsesRequest,
	startTime time.Time,
	reqLogManager *requestlog.Manager,
	requestLogID string,
	usageManager *quota.UsageManager,
	allowedChannels []int,
) {
	// è·å–å½“å‰ Responses ä¸Šæ¸¸é…ç½®
	upstream, err := cfgManager.GetCurrentResponsesUpstream()
	if err != nil {
		c.JSON(503, gin.H{
			"error": "æœªé…ç½®ä»»ä½• Responses æ¸ é“ï¼Œè¯·å…ˆåœ¨ç®¡ç†ç•Œé¢æ·»åŠ æ¸ é“",
			"code":  "NO_RESPONSES_UPSTREAM",
		})
		return
	}

	// Check if this channel is allowed by API key permissions
	if len(allowedChannels) > 0 {
		allowed := false
		for _, idx := range allowedChannels {
			if idx == upstream.Index {
				allowed = true
				break
			}
		}
		if !allowed {
			c.JSON(403, gin.H{
				"error": fmt.Sprintf("Channel %s (index %d) not allowed for this API key", upstream.Name, upstream.Index),
				"code":  "CHANNEL_NOT_ALLOWED",
			})
			return
		}
	}

	// å¤„ç† OpenAI OAuth æ¸ é“ï¼ˆCodexï¼‰
	if upstream.ServiceType == "openai-oauth" {
		success, failoverErr := tryResponsesChannelWithOAuth(c, envCfg, cfgManager, sessionManager, upstream, bodyBytes, responsesReq, startTime, reqLogManager, requestLogID, usageManager)
		if !success && failoverErr != nil {
			status := failoverErr.Status
			if status == 0 {
				status = 500
			}
			var errBody map[string]interface{}
			if err := json.Unmarshal(failoverErr.Body, &errBody); err == nil {
				c.JSON(status, errBody)
			} else {
				c.JSON(status, gin.H{"error": string(failoverErr.Body)})
			}
		}
		return
	}

	if len(upstream.APIKeys) == 0 {
		c.JSON(503, gin.H{
			"error": fmt.Sprintf("å½“å‰ Responses æ¸ é“ \"%s\" æœªé…ç½®APIå¯†é’¥", upstream.Name),
			"code":  "NO_API_KEYS",
		})
		return
	}

	provider := &providers.ResponsesProvider{SessionManager: sessionManager}

	maxRetries := len(upstream.APIKeys)
	failedKeys := make(map[string]bool)
	var lastError error
	var lastOriginalBodyBytes []byte
	var lastFailoverError *struct {
		Status int
		Body   []byte
	}
	deprioritizeCandidates := make(map[string]bool)

	for attempt := 0; attempt < maxRetries; attempt++ {
		c.Request.Body = io.NopCloser(bytes.NewReader(bodyBytes))

		apiKey, err := cfgManager.GetNextResponsesAPIKey(upstream, failedKeys)
		if err != nil {
			lastError = err
			break
		}

		if envCfg.ShouldLog("info") {
			log.Printf("ğŸ¯ ä½¿ç”¨ Responses ä¸Šæ¸¸: %s - %s (å°è¯• %d/%d)", upstream.Name, upstream.BaseURL, attempt+1, maxRetries)
			log.Printf("ğŸ”‘ ä½¿ç”¨APIå¯†é’¥: %s", maskAPIKey(apiKey))
		}

		providerReq, originalBodyBytes, err := provider.ConvertToProviderRequest(c, upstream, apiKey)
		if err != nil {
			lastError = err
			failedKeys[apiKey] = true
			if originalBodyBytes != nil {
				lastOriginalBodyBytes = originalBodyBytes
			}
			continue
		}
		lastOriginalBodyBytes = originalBodyBytes

		if envCfg.EnableRequestLogs {
			log.Printf("ğŸ“¥ æ”¶åˆ° Responses è¯·æ±‚: %s %s", c.Request.Method, c.Request.URL.Path)
			if envCfg.IsDevelopment() {
				formattedBody := utils.FormatJSONBytesForLog(lastOriginalBodyBytes, 500)
				log.Printf("ğŸ“„ åŸå§‹è¯·æ±‚ä½“:\n%s", formattedBody)

				sanitizedHeaders := make(map[string]string)
				for key, values := range c.Request.Header {
					if len(values) > 0 {
						sanitizedHeaders[key] = values[0]
					}
				}
				maskedHeaders := utils.MaskSensitiveHeaders(sanitizedHeaders)
				headersJSON, _ := json.MarshalIndent(maskedHeaders, "", "  ")
				log.Printf("ğŸ“¥ åŸå§‹è¯·æ±‚å¤´:\n%s", string(headersJSON))
			}
		}

		resp, err := sendResponsesRequest(providerReq, upstream, envCfg, responsesReq.Stream)
		if err != nil {
			lastError = err
			failedKeys[apiKey] = true
			cfgManager.MarkKeyAsFailed(apiKey)
			log.Printf("âš ï¸ APIå¯†é’¥å¤±è´¥: %v", err)
			continue
		}

		if resp.StatusCode < 200 || resp.StatusCode >= 300 {
			respBodyBytes, _ := io.ReadAll(resp.Body)
			resp.Body.Close()
			respBodyBytes = utils.DecompressGzipIfNeeded(resp, respBodyBytes)

			shouldFailover, isQuotaRelated := shouldRetryWithNextKey(resp.StatusCode, respBodyBytes)
			if shouldFailover {
				lastError = fmt.Errorf("ä¸Šæ¸¸é”™è¯¯: %d", resp.StatusCode)
				failedKeys[apiKey] = true
				cfgManager.MarkKeyAsFailed(apiKey)

				log.Printf("âš ï¸ Responses APIå¯†é’¥å¤±è´¥ (çŠ¶æ€: %d)ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå¯†é’¥", resp.StatusCode)
				if envCfg.EnableResponseLogs && envCfg.IsDevelopment() {
					formattedBody := utils.FormatJSONBytesForLog(respBodyBytes, 500)
					log.Printf("ğŸ“¦ å¤±è´¥åŸå› :\n%s", formattedBody)
				} else if envCfg.EnableResponseLogs {
					log.Printf("å¤±è´¥åŸå› : %s", string(respBodyBytes))
				}

				lastFailoverError = &struct {
					Status int
					Body   []byte
				}{
					Status: resp.StatusCode,
					Body:   respBodyBytes,
				}

				if isQuotaRelated {
					deprioritizeCandidates[apiKey] = true
				}
				continue
			}

			if envCfg.EnableResponseLogs {
				log.Printf("âš ï¸ Responses ä¸Šæ¸¸è¿”å›é”™è¯¯: %d", resp.StatusCode)
				if envCfg.IsDevelopment() {
					formattedBody := utils.FormatJSONBytesForLog(respBodyBytes, 500)
					log.Printf("ğŸ“¦ é”™è¯¯å“åº”ä½“:\n%s", formattedBody)

					respHeaders := make(map[string]string)
					for key, values := range resp.Header {
						if len(values) > 0 {
							respHeaders[key] = values[0]
						}
					}
					respHeadersJSON, _ := json.MarshalIndent(respHeaders, "", "  ")
					log.Printf("ğŸ“‹ é”™è¯¯å“åº”å¤´:\n%s", string(respHeadersJSON))
				}
			}
			c.Data(resp.StatusCode, "application/json", respBodyBytes)
			return
		}

		if len(deprioritizeCandidates) > 0 {
			for key := range deprioritizeCandidates {
				if err := cfgManager.DeprioritizeAPIKey(key); err != nil {
					log.Printf("âš ï¸ å¯†é’¥é™çº§å¤±è´¥: %v", err)
				}
			}
		}

		handleResponsesSuccess(c, resp, provider, upstream, envCfg, cfgManager, sessionManager, startTime, &responsesReq, bodyBytes, reqLogManager, requestLogID, usageManager)
		return
	}

	log.Printf("ğŸ’¥ æ‰€æœ‰ Responses APIå¯†é’¥éƒ½å¤±è´¥äº†")

	if lastFailoverError != nil {
		status := lastFailoverError.Status
		if status == 0 {
			status = 500
		}
		var errBody map[string]interface{}
		if err := json.Unmarshal(lastFailoverError.Body, &errBody); err == nil {
			c.JSON(status, errBody)
		} else {
			c.JSON(status, gin.H{"error": string(lastFailoverError.Body)})
		}
	} else {
		errMsg := "æœªçŸ¥é”™è¯¯"
		if lastError != nil {
			errMsg = lastError.Error()
		}
		c.JSON(500, gin.H{
			"error":   "æ‰€æœ‰ä¸Šæ¸¸ Responses APIå¯†é’¥éƒ½ä¸å¯ç”¨",
			"details": errMsg,
		})
	}
}

// sendResponsesRequest å‘é€ Responses è¯·æ±‚
func sendResponsesRequest(req *http.Request, upstream *config.UpstreamConfig, envCfg *config.EnvConfig, isStream bool) (*http.Response, error) {
	clientManager := httpclient.GetManager()

	var client *http.Client
	if isStream {
		// æµå¼è¯·æ±‚ï¼šä½¿ç”¨æ— è¶…æ—¶çš„æµå¼å®¢æˆ·ç«¯ï¼Œä½†æœ‰å“åº”å¤´è¶…æ—¶
		client = clientManager.GetStreamClient(upstream.InsecureSkipVerify, upstream.GetResponseHeaderTimeout())
	} else {
		// éæµå¼è¯·æ±‚ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼ŒåŒæ—¶åº”ç”¨æ¸ é“çš„å“åº”å¤´è¶…æ—¶è®¾ç½®
		timeout := time.Duration(envCfg.RequestTimeout) * time.Millisecond
		client = clientManager.GetStandardClient(timeout, upstream.InsecureSkipVerify, upstream.GetResponseHeaderTimeout())
	}

	if upstream.InsecureSkipVerify && envCfg.EnableRequestLogs {
		log.Printf("âš ï¸ æ­£åœ¨è·³è¿‡å¯¹ %s çš„TLSè¯ä¹¦éªŒè¯", req.URL.String())
	}

	if envCfg.EnableRequestLogs {
		log.Printf("ğŸŒ å®é™…è¯·æ±‚URL: %s", req.URL.String())
		log.Printf("ğŸ“¤ è¯·æ±‚æ–¹æ³•: %s", req.Method)
		if envCfg.IsDevelopment() {
			// å¯¹è¯·æ±‚å¤´åšæ•æ„Ÿä¿¡æ¯è„±æ•
			reqHeaders := make(map[string]string)
			for key, values := range req.Header {
				if len(values) > 0 {
					reqHeaders[key] = values[0]
				}
			}
			maskedReqHeaders := utils.MaskSensitiveHeaders(reqHeaders)
			reqHeadersJSON, _ := json.MarshalIndent(maskedReqHeaders, "", "  ")
			log.Printf("ğŸ“‹ å®é™…è¯·æ±‚å¤´:\n%s", string(reqHeadersJSON))

			if req.Body != nil {
				// è¯»å–è¯·æ±‚ä½“ç”¨äºæ—¥å¿—
				bodyBytes, err := io.ReadAll(req.Body)
				if err == nil {
					// æ¢å¤è¯·æ±‚ä½“
					req.Body = io.NopCloser(bytes.NewReader(bodyBytes))

					// ä½¿ç”¨æ™ºèƒ½æˆªæ–­å’Œç®€åŒ–å‡½æ•°ï¼ˆä¸TSç‰ˆæœ¬å¯¹é½ï¼‰
					formattedBody := utils.FormatJSONBytesForLog(bodyBytes, 500)
					log.Printf("ğŸ“¦ å®é™…è¯·æ±‚ä½“:\n%s", formattedBody)
				}
			}
		}
	}

	return client.Do(req)
}

// handleResponsesSuccess å¤„ç†æˆåŠŸçš„ Responses å“åº”
func handleResponsesSuccess(
	c *gin.Context,
	resp *http.Response,
	provider *providers.ResponsesProvider,
	upstream *config.UpstreamConfig,
	envCfg *config.EnvConfig,
	cfgManager *config.ConfigManager,
	sessionManager *session.SessionManager,
	startTime time.Time,
	originalReq *types.ResponsesRequest,
	originalRequestJSON []byte, // åŸå§‹è¯·æ±‚ JSONï¼Œç”¨äº Chat â†’ Responses è½¬æ¢
	reqLogManager *requestlog.Manager,
	requestLogID string,
	usageManager *quota.UsageManager,
) {
	defer resp.Body.Close()

	upstreamType := upstream.ServiceType

	// æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼å“åº”
	isStream := originalReq != nil && originalReq.Stream

	if isStream {
		// æµå¼å“åº”å¤„ç†
		if envCfg.EnableResponseLogs {
			responseTime := time.Since(startTime).Milliseconds()
			log.Printf("â±ï¸ Responses æµå¼å“åº”å¼€å§‹: %dms, çŠ¶æ€: %d", responseTime, resp.StatusCode)
		}

		// å…ˆè½¬å‘ä¸Šæ¸¸å“åº”å¤´ï¼ˆé€æ˜ä»£ç†ï¼‰
		utils.ForwardResponseHeaders(resp.Header, c.Writer)

		// è®¾ç½®SSEå“åº”å¤´ï¼ˆå¯èƒ½è¦†ç›–ä¸Šæ¸¸çš„ Content-Typeï¼‰
		c.Header("Content-Type", "text/event-stream")
		c.Header("Cache-Control", "no-cache")
		c.Header("Connection", "keep-alive")
		c.Header("X-Accel-Buffering", "no")

		// åˆ›å»ºæµå¼å†…å®¹åˆæˆå™¨ï¼ˆä»…åœ¨å¼€å‘æ¨¡å¼å¹¶å¼€å¯å“åº”æ—¥å¿—æ—¶ï¼‰
		var synthesizer *utils.StreamSynthesizer
		var logBuffer bytes.Buffer
		streamLoggingEnabled := envCfg.IsDevelopment() && envCfg.EnableResponseLogs

		// Check if debug logging is enabled (need to capture response body)
		debugLogEnabled := cfgManager.GetDebugLogConfig().Enabled

		// å¯¹äº responses ç±»å‹ï¼ˆåŒ…æ‹¬ openai-oauthï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ synthesizer æ¥æå– usageï¼Œä¸è®ºæ—¥å¿—æ˜¯å¦å¯ç”¨
		needsSynthesizer := (upstreamType == "responses" || upstreamType == "openai-oauth") && reqLogManager != nil
		if streamLoggingEnabled || needsSynthesizer {
			synthesizer = utils.NewStreamSynthesizer(upstreamType)
		}

		// åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢ï¼šé responses ç±»å‹çš„ä¸Šæ¸¸éœ€è¦ä» Chat Completions è½¬æ¢ä¸º Responses æ ¼å¼
		// openai-oauth ä½¿ç”¨ Responses API æ ¼å¼ï¼Œä¸éœ€è¦è½¬æ¢
		needConvert := upstreamType != "responses" && upstreamType != "openai-oauth"
		var converterState any

		// è½¬å‘æµå¼å“åº”å¹¶è®°å½•å†…å®¹
		c.Status(resp.StatusCode)
		flusher, _ := c.Writer.(http.Flusher)

		scanner := bufio.NewScanner(resp.Body)
		// å¢åŠ ç¼“å†²åŒºå¤§å°ï¼šåˆå§‹64KBï¼Œæœ€å¤§1MB
		const maxCapacity = 1024 * 1024 // 1MB
		buf := make([]byte, 0, 64*1024) // åˆå§‹64KB
		scanner.Buffer(buf, maxCapacity)

		// ç”¨äºæå– Codex usage çš„å˜é‡
		var codexUsage *CodexUsage
		var responseModel string

		for scanner.Scan() {
			line := scanner.Text()

			// è®°å½•æ—¥å¿—ï¼ˆä»…åœ¨å¼€å‘æ¨¡å¼ä¸‹æˆ–è°ƒè¯•æ—¥å¿—å¯ç”¨æ—¶ï¼‰
			if streamLoggingEnabled || debugLogEnabled {
				logBuffer.WriteString(line + "\n")
			}
			if synthesizer != nil {
				synthesizer.ProcessLine(line)
			}

			// å¯¹äº responses/openai-oauth ç±»å‹ï¼Œå°è¯•ä» response.completed äº‹ä»¶ä¸­æå– usage
			if (upstreamType == "responses" || upstreamType == "openai-oauth") && reqLogManager != nil {
				if usage, model := extractCodexUsageFromSSE(line); usage != nil {
					codexUsage = usage
					if model != "" {
						responseModel = model
					}
				}
			}

			if needConvert {
				// è°ƒç”¨è½¬æ¢å™¨å°† Chat Completions SSE è½¬æ¢ä¸º Responses SSE
				events := converters.ConvertOpenAIChatToResponses(
					c.Request.Context(),
					originalReq.Model,
					originalRequestJSON,
					nil,
					[]byte(line),
					&converterState,
				)
				for _, event := range events {
					_, err := c.Writer.Write([]byte(event))
					if err != nil {
						log.Printf("âš ï¸ æµå¼å“åº”ä¼ è¾“é”™è¯¯: %v", err)
						break
					}
				}
			} else {
				// ç›´æ¥é€ä¼  Responses æ ¼å¼çš„æµ
				_, err := c.Writer.Write([]byte(line + "\n"))
				if err != nil {
					log.Printf("âš ï¸ æµå¼å“åº”ä¼ è¾“é”™è¯¯: %v", err)
					break
				}
			}

			if flusher != nil {
				flusher.Flush()
			}
		}

		if err := scanner.Err(); err != nil {
			log.Printf("âš ï¸ æµå¼å“åº”è¯»å–é”™è¯¯: %v", err)
		}

		completeTime := time.Now()
		durationMs := completeTime.Sub(startTime).Milliseconds()

		if envCfg.EnableResponseLogs {
			log.Printf("âœ… Responses æµå¼å“åº”å®Œæˆ: %dms", durationMs)

			// æ‰“å°å®Œæ•´çš„å“åº”å†…å®¹
			if envCfg.IsDevelopment() {
				if synthesizer != nil {
					synthesizedContent := synthesizer.GetSynthesizedContent()
					parseFailed := synthesizer.IsParseFailed()
					if synthesizedContent != "" && !parseFailed {
						log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åˆæˆå†…å®¹:\n%s", strings.TrimSpace(synthesizedContent))
					} else if logBuffer.Len() > 0 {
						log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åŸå§‹å†…å®¹:\n%s", logBuffer.String())
					}
				} else if logBuffer.Len() > 0 {
					// synthesizerä¸ºnilæ—¶ï¼Œç›´æ¥æ‰“å°åŸå§‹å†…å®¹
					log.Printf("ğŸ›°ï¸  ä¸Šæ¸¸æµå¼å“åº”åŸå§‹å†…å®¹:\n%s", logBuffer.String())
				}
			}
		}

		// æ›´æ–°è¯·æ±‚æ—¥å¿—ï¼ˆResponses APIï¼‰
		if reqLogManager != nil && requestLogID != "" {
			// ç”¨äºå®šä»·è®¡ç®—çš„æ¨¡å‹åï¼ˆä¼˜å…ˆå“åº”æ¨¡å‹ï¼Œè‹¥æ— å®šä»·é…ç½®åˆ™å›é€€åˆ°è¯·æ±‚æ¨¡å‹ï¼‰
			pricingModel := responseModel
			if pricingModel == "" {
				pricingModel = originalReq.Model
			} else if pm := pricing.GetManager(); pm != nil && !pm.HasPricing(pricingModel) && originalReq.Model != "" {
				// å“åº”æ¨¡å‹æ— å®šä»·é…ç½®ï¼Œå›é€€åˆ°è¯·æ±‚æ¨¡å‹
				pricingModel = originalReq.Model
			}

			record := &requestlog.RequestLog{
				Status:        requestlog.StatusCompleted,
				CompleteTime:  completeTime,
				DurationMs:    durationMs,
				Type:          upstreamType,
				ProviderName:  upstream.Name,
				ResponseModel: responseModel,
				HTTPStatus:    resp.StatusCode,
				ChannelID:     upstream.Index,
				ChannelName:   upstream.Name,
			}

			if codexUsage != nil {
				// Codex çš„ input_tokens å·²åŒ…å« cached_tokensï¼Œéœ€è¦å‡å»å¾—åˆ°å®é™…æ–°è¾“å…¥
				actualInput := codexUsage.InputTokens - codexUsage.CachedTokens
				if actualInput < 0 {
					actualInput = 0
				}
				record.InputTokens = actualInput
				record.OutputTokens = codexUsage.OutputTokens
				record.CacheReadInputTokens = codexUsage.CachedTokens
				record.CacheCreationInputTokens = 0

				// è®¡ç®—æˆæœ¬ï¼šä½¿ç”¨ pricingModelï¼ˆä¼˜å…ˆå“åº”æ¨¡å‹ï¼Œæ— å®šä»·é…ç½®åˆ™å›é€€åˆ°è¯·æ±‚æ¨¡å‹ï¼‰
				if pm := pricing.GetManager(); pm != nil {
					var multipliers *pricing.PriceMultipliers
					if channelMult := upstream.GetPriceMultipliers(pricingModel); channelMult != nil {
						multipliers = &pricing.PriceMultipliers{
							InputMultiplier:         channelMult.GetEffectiveMultiplier("input"),
							OutputMultiplier:        channelMult.GetEffectiveMultiplier("output"),
							CacheCreationMultiplier: channelMult.GetEffectiveMultiplier("cacheCreation"),
							CacheReadMultiplier:     channelMult.GetEffectiveMultiplier("cacheRead"),
						}
					}
					breakdown := pm.CalculateCostWithBreakdown(
						pricingModel,
						actualInput,
						codexUsage.OutputTokens,
						0,
						codexUsage.CachedTokens,
						multipliers,
					)
					record.Price = breakdown.TotalCost
					record.InputCost = breakdown.InputCost
					record.OutputCost = breakdown.OutputCost
					record.CacheCreationCost = 0
					record.CacheReadCost = breakdown.CacheReadCost
				}
			}

			if err := reqLogManager.Update(requestLogID, record); err != nil {
				log.Printf("âš ï¸ è¯·æ±‚æ—¥å¿—æ›´æ–°å¤±è´¥: %v", err)
			}

			// Save debug log if enabled (use logBuffer for stream response body)
			SaveDebugLog(c, cfgManager, reqLogManager, requestLogID, resp.StatusCode, resp.Header, logBuffer.Bytes())

			// Track usage for quota (streaming response completed)
			trackResponsesUsage(usageManager, upstream, originalReq.Model, record.Price)
		}
		return
	}

	// éæµå¼å“åº”å¤„ç†(åŸæœ‰é€»è¾‘)
	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		c.JSON(500, gin.H{"error": "Failed to read response"})
		return
	}

	completeTime := time.Now()
	durationMs := completeTime.Sub(startTime).Milliseconds()

	if envCfg.EnableResponseLogs {
		log.Printf("â±ï¸ Responses å“åº”å®Œæˆ: %dms, çŠ¶æ€: %d", durationMs, resp.StatusCode)
		if envCfg.IsDevelopment() {
			// å“åº”å¤´(ä¸éœ€è¦è„±æ•)
			respHeaders := make(map[string]string)
			for key, values := range resp.Header {
				if len(values) > 0 {
					respHeaders[key] = values[0]
				}
			}
			respHeadersJSON, _ := json.MarshalIndent(respHeaders, "", "  ")
			log.Printf("ğŸ“‹ å“åº”å¤´:\n%s", string(respHeadersJSON))

			formattedBody := utils.FormatJSONBytesForLog(bodyBytes, 500)
			log.Printf("ğŸ“¦ å“åº”ä½“:\n%s", formattedBody)
		}
	}

	providerResp := &types.ProviderResponse{
		StatusCode: resp.StatusCode,
		Headers:    resp.Header,
		Body:       bodyBytes,
		Stream:     false,
	}

	// è½¬æ¢ä¸º Responses æ ¼å¼
	responsesResp, err := provider.ConvertToResponsesResponse(providerResp, upstreamType, "")
	if err != nil {
		c.JSON(500, gin.H{"error": "Failed to convert response"})
		return
	}

	// æ›´æ–°è¯·æ±‚æ—¥å¿—ï¼ˆéæµå¼ Responses APIï¼ŒåŒ…æ‹¬ openai-oauthï¼‰
	if reqLogManager != nil && requestLogID != "" && (upstreamType == "responses" || upstreamType == "openai-oauth") {
		// ä»éæµå¼å“åº”ä¸­æå– usage
		codexUsage, responseModel := extractCodexUsageFromJSON(bodyBytes)

		// ç”¨äºå®šä»·è®¡ç®—çš„æ¨¡å‹åï¼ˆä¼˜å…ˆå“åº”æ¨¡å‹ï¼Œè‹¥æ— å®šä»·é…ç½®åˆ™å›é€€åˆ°è¯·æ±‚æ¨¡å‹ï¼‰
		pricingModel := responseModel
		if pricingModel == "" {
			pricingModel = originalReq.Model
		} else if pm := pricing.GetManager(); pm != nil && !pm.HasPricing(pricingModel) && originalReq.Model != "" {
			// å“åº”æ¨¡å‹æ— å®šä»·é…ç½®ï¼Œå›é€€åˆ°è¯·æ±‚æ¨¡å‹
			pricingModel = originalReq.Model
		}

		record := &requestlog.RequestLog{
			Status:        requestlog.StatusCompleted,
			CompleteTime:  completeTime,
			DurationMs:    durationMs,
			Type:          upstreamType,
			ProviderName:  upstream.Name,
			ResponseModel: responseModel,
			HTTPStatus:    resp.StatusCode,
			ChannelID:     upstream.Index,
			ChannelName:   upstream.Name,
		}

		if codexUsage != nil {
			// Codex çš„ input_tokens å·²åŒ…å« cached_tokensï¼Œéœ€è¦å‡å»å¾—åˆ°å®é™…æ–°è¾“å…¥
			actualInput := codexUsage.InputTokens - codexUsage.CachedTokens
			if actualInput < 0 {
				actualInput = 0
			}
			record.InputTokens = actualInput
			record.OutputTokens = codexUsage.OutputTokens
			record.CacheReadInputTokens = codexUsage.CachedTokens
			record.CacheCreationInputTokens = 0

			// è®¡ç®—æˆæœ¬ï¼šä½¿ç”¨ pricingModelï¼ˆä¼˜å…ˆå“åº”æ¨¡å‹ï¼Œæ— å®šä»·é…ç½®åˆ™å›é€€åˆ°è¯·æ±‚æ¨¡å‹ï¼‰
			if pm := pricing.GetManager(); pm != nil {
				var multipliers *pricing.PriceMultipliers
				if channelMult := upstream.GetPriceMultipliers(pricingModel); channelMult != nil {
					multipliers = &pricing.PriceMultipliers{
						InputMultiplier:         channelMult.GetEffectiveMultiplier("input"),
						OutputMultiplier:        channelMult.GetEffectiveMultiplier("output"),
						CacheCreationMultiplier: channelMult.GetEffectiveMultiplier("cacheCreation"),
						CacheReadMultiplier:     channelMult.GetEffectiveMultiplier("cacheRead"),
					}
				}
				breakdown := pm.CalculateCostWithBreakdown(
					pricingModel,
					actualInput,
					codexUsage.OutputTokens,
					0,
					codexUsage.CachedTokens,
					multipliers,
				)
				record.Price = breakdown.TotalCost
				record.InputCost = breakdown.InputCost
				record.OutputCost = breakdown.OutputCost
				record.CacheCreationCost = 0
				record.CacheReadCost = breakdown.CacheReadCost
			}
		}

		if err := reqLogManager.Update(requestLogID, record); err != nil {
			log.Printf("âš ï¸ è¯·æ±‚æ—¥å¿—æ›´æ–°å¤±è´¥: %v", err)
		}

		// Save debug log if enabled
		SaveDebugLog(c, cfgManager, reqLogManager, requestLogID, resp.StatusCode, resp.Header, bodyBytes)

		// Track usage for quota (count 2xx and 400 as successful - 400 is client error but still counts as a request)
		if (resp.StatusCode >= 200 && resp.StatusCode < 300) || resp.StatusCode == 400 {
			trackResponsesUsage(usageManager, upstream, originalReq.Model, record.Price)
		}
	}

	// æ›´æ–°ä¼šè¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
	if originalReq.Store == nil || *originalReq.Store {
		// è·å–ä¼šè¯
		sess, err := sessionManager.GetOrCreateSession(originalReq.PreviousResponseID)
		if err == nil {
			previousID := sess.LastResponseID

			// è¿½åŠ ç”¨æˆ·è¾“å…¥
			inputItems, _ := parseInputToItems(originalReq.Input)
			for _, item := range inputItems {
				sessionManager.AppendMessage(sess.ID, item, 0)
			}

			// è¿½åŠ åŠ©æ‰‹å“åº”
			for _, item := range responsesResp.Output {
				sessionManager.AppendMessage(sess.ID, item, 0)
			}

			// ä»…åœ¨æ¯æ¬¡å“åº”å®Œæˆåç´¯è®¡ä¸€æ¬¡ tokenï¼ˆé¿å…æŒ‰è¾“å‡ºé¡¹é‡å¤ç´¯è®¡ï¼‰
			sessionManager.AddTokens(sess.ID, responsesResp.Usage.TotalTokens)

			// æ›´æ–° last response ID
			sessionManager.UpdateLastResponseID(sess.ID, responsesResp.ID)

			// è®°å½•æ˜ å°„
			sessionManager.RecordResponseMapping(responsesResp.ID, sess.ID)

			// è®¾ç½® previous_id
			if previousID != "" {
				responsesResp.PreviousID = previousID
			}
		}
	}

	// è½¬å‘ä¸Šæ¸¸å“åº”å¤´åˆ°å®¢æˆ·ç«¯ï¼ˆé€æ˜ä»£ç†ï¼‰
	utils.ForwardResponseHeaders(resp.Header, c.Writer)

	c.JSON(200, responsesResp)
}

// CodexUsage Codex API çš„ usage ç»“æ„
type CodexUsage struct {
	InputTokens  int
	OutputTokens int
	CachedTokens int
	TotalTokens  int
}

// extractCodexUsageFromSSE ä» SSE äº‹ä»¶è¡Œä¸­æå– Codex usage æ•°æ®
// è¿”å› usage å’Œ modelï¼Œå¦‚æœä¸æ˜¯ response.completed äº‹ä»¶åˆ™è¿”å› nil
func extractCodexUsageFromSSE(line string) (*CodexUsage, string) {
	// SSE æ ¼å¼: "data: {...}" æˆ– "data:{...}"
	var jsonStr string
	if strings.HasPrefix(line, "data: ") {
		jsonStr = strings.TrimPrefix(line, "data: ")
	} else if strings.HasPrefix(line, "data:") {
		jsonStr = strings.TrimPrefix(line, "data:")
	} else {
		return nil, ""
	}
	if jsonStr == "[DONE]" {
		return nil, ""
	}

	var event struct {
		Type     string `json:"type"`
		Response struct {
			Model string `json:"model"`
			Usage struct {
				InputTokens        int `json:"input_tokens"`
				InputTokensDetails struct {
					CachedTokens int `json:"cached_tokens"`
				} `json:"input_tokens_details"`
				OutputTokens int `json:"output_tokens"`
				TotalTokens  int `json:"total_tokens"`
			} `json:"usage"`
		} `json:"response"`
	}

	if err := json.Unmarshal([]byte(jsonStr), &event); err != nil {
		return nil, ""
	}

	// åªå¤„ç† response.completed äº‹ä»¶
	if event.Type != "response.completed" {
		return nil, ""
	}

	return &CodexUsage{
		InputTokens:  event.Response.Usage.InputTokens,
		OutputTokens: event.Response.Usage.OutputTokens,
		CachedTokens: event.Response.Usage.InputTokensDetails.CachedTokens,
		TotalTokens:  event.Response.Usage.TotalTokens,
	}, event.Response.Model
}

// extractCodexUsageFromJSON ä»éæµå¼ JSON å“åº”ä¸­æå– Codex usage æ•°æ®
func extractCodexUsageFromJSON(body []byte) (*CodexUsage, string) {
	var resp struct {
		Model string `json:"model"`
		Usage struct {
			InputTokens        int `json:"input_tokens"`
			InputTokensDetails struct {
				CachedTokens int `json:"cached_tokens"`
			} `json:"input_tokens_details"`
			OutputTokens int `json:"output_tokens"`
			TotalTokens  int `json:"total_tokens"`
		} `json:"usage"`
	}

	if err := json.Unmarshal(body, &resp); err != nil {
		return nil, ""
	}

	return &CodexUsage{
		InputTokens:  resp.Usage.InputTokens,
		OutputTokens: resp.Usage.OutputTokens,
		CachedTokens: resp.Usage.InputTokensDetails.CachedTokens,
		TotalTokens:  resp.Usage.TotalTokens,
	}, resp.Model
}

// parseInputToItems è§£æ input ä¸º ResponsesItem æ•°ç»„
func parseInputToItems(input interface{}) ([]types.ResponsesItem, error) {
	switch v := input.(type) {
	case string:
		return []types.ResponsesItem{{Type: "text", Content: v}}, nil
	case []interface{}:
		items := []types.ResponsesItem{}
		for _, item := range v {
			itemMap, ok := item.(map[string]interface{})
			if !ok {
				continue
			}
			itemType, _ := itemMap["type"].(string)
			content := itemMap["content"]
			items = append(items, types.ResponsesItem{Type: itemType, Content: content})
		}
		return items, nil
	default:
		return nil, fmt.Errorf("unsupported input type")
	}
}

// extractConversationID ä»è¯·æ±‚ä¸­æå–å¯¹è¯æ ‡è¯†ï¼ˆç”¨äº Responses API æ¸ é“äº²å’Œï¼‰
// ä¼˜å…ˆçº§: Conversation_id Header > Session_id Header > prompt_cache_key > metadata.user_id
func extractConversationID(c *gin.Context, bodyBytes []byte) string {
	// 1. HTTP Header: Conversation_id
	if convID := c.GetHeader("Conversation_id"); convID != "" {
		return convID
	}

	// 2. HTTP Header: Session_id
	if sessID := c.GetHeader("Session_id"); sessID != "" {
		return sessID
	}

	// 3. Request Body: prompt_cache_key æˆ– metadata.user_id
	var req struct {
		PromptCacheKey string `json:"prompt_cache_key"`
		Metadata       struct {
			UserID string `json:"user_id"`
		} `json:"metadata"`
	}
	if err := json.Unmarshal(bodyBytes, &req); err == nil {
		if req.PromptCacheKey != "" {
			return req.PromptCacheKey
		}
		// 4. Fallback: metadata.user_id
		if req.Metadata.UserID != "" {
			return req.Metadata.UserID
		}
	}

	return ""
}

func isCodexResponsesModel(model string) bool {
	model = strings.ToLower(strings.TrimSpace(model))
	return strings.Contains(model, "codex")
}
